{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ニューラルネットワークの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# 損失関数\n",
    "#\n",
    "\n",
    "def mean_squared_error(y, t):\n",
    "    \"\"\" 2乗和誤差 \"\"\"\n",
    "    return 0.5 * np.sum((y-t)**2)\n",
    "\n",
    "def cross_entropy_error(y, t):\n",
    "    \"\"\" 交差エントロピー誤差 \"\"\"\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y + delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morison/.local/lib/python3.10/site-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n",
      "(60000, 784)\n",
      "(60000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# OpenMLからMNISTを取ってきて標準化とOne-hot Encodingを行う\n",
    "#\n",
    "\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784')\n",
    "X, y = mnist['data'], mnist['target']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "X, y = X.values, y.values\n",
    "\n",
    "# 標準化\n",
    "X /= 255.0\n",
    "# one-hot encoding\n",
    "T = np.zeros((y.shape[0], 10))\n",
    "for idx, row in enumerate(T):\n",
    "    row[int(y[idx])] = 1\n",
    "x_train, t_train = X[:60000], T[:60000]\n",
    "x_test, t_test = X[60000:], T[60000:]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)\n",
    "print(x_test.shape)\n",
    "print(t_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 784)\n",
      "(10, 10)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# ミニバッチ学習(大量のデータから一部をサンプリングし，全体の近似として学習)\n",
    "#\n",
    "\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]\n",
    "print(x_batch.shape)\n",
    "print(t_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# 画像見てみる\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# 交差エントロピーのミニバッチ対応版\n",
    "#\n",
    "\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        # データ1つに対してのみ計算する場合\n",
    "        t = t.reshape(1, t.shape[1])\n",
    "        y = y.reshape(1, y.shape[1])\n",
    "    batch_size = y.shape[0]\n",
    "    # バッチサイズで割って，画像一枚当たりの平均を出す\n",
    "    return np.sum(t * np.log(t + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ソフトマックス関数\n",
    "#\n",
    "\n",
    "def softmax(a):\n",
    "    c = np.max(a) # オーバーフロー対策\n",
    "    exp_a = np.sum(a - c)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    return y\n",
    "\n",
    "#\n",
    "# 数値微分\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 損失関数をネットワークの重みで偏微分し，損失関数を最小化する方向に重みを更新する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# [TODO] 単層ネットワークで勾配を計算してみる\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# [TODO] 2層のNNクラスの実装\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
